{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca03192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai #already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81fca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73056916",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'Your_API_KEY'  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6be4f",
   "metadata": {},
   "source": [
    "Please be advised that the current model version is subject to updates and improvements over time. In the event of model deprecation, we recommend referring to the provided link for access to the latest and most suitable model for your needs: [OpenAI Model Documentation](https://platform.openai.com/docs/models).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef4a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_response(message, max_tokens=200):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n",
    "                  {\"role\": \"user\", \"content\": message}],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341f5d2",
   "metadata": {},
   "source": [
    "Model: OpenAI API - gpt-3.5-turbo\n",
    "\n",
    "This code defines a function called get_gpt_response that takes in a message and an optional argument max_tokens. The function makes use of the OpenAI API to generate a response based on the given message.\n",
    "\n",
    "## Here is a line-by-line explanation of the code in the get_gpt_response function:\n",
    "\n",
    "1. def get_gpt_response(message, max_tokens=200): - This line defines the function get_gpt_response with two parameters: message and max_tokens, which has a default value of 200.\n",
    "\n",
    "2. response = openai.ChatCompletion.create( - This line creates a chat completion request using the OpenAI API.\n",
    "\n",
    "3. model=\"gpt-3.5-turbo\", - This specifies the model to use for generating the response. In this case, it uses the \"gpt-3.5-turbo\" model.\n",
    "\n",
    "4. messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, - This provides a list of messages to the API. The first message, with the role \"system\", provides a prompt that sets the system-level instruction.\n",
    "\n",
    "5. {\"role\": \"user\", \"content\": message}], - This adds a user message to the list of messages. The content of this message is the input message parameter passed into the function.\n",
    "\n",
    "6. max_tokens=max_tokens, - This sets the maximum number of tokens to generate in the response. By default, it's set to 200, but it can be overridden by providing a different value for the max_tokens parameter when calling the function.\n",
    "\n",
    "7. temperature=0.7 - This sets the \"temperature\" for the response generation, controlling the randomness of the output. A higher value (e.g., 0.7) leads to more random responses, while a lower value (e.g., 0.2) makes the responses more focused and deterministic.\n",
    "\n",
    "8. ) - The closing parentheses for the openai.ChatCompletion.create function call.\n",
    "\n",
    "9. return response['choices'][0]['message']['content'] - This line returns the generated response from the API call. The response is accessed using dictionary-like indexing to retrieve the content of the message.\n",
    "\n",
    "In the provided code, the get_gpt_response function is called multiple times with different prompts, and the generated response is printed using the print function. However, since the STDOUT and result of the focal cell are not provided, I cannot tell what the exact output would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49fd4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several key benefits of using renewable energy:\n",
      "\n",
      "1. Environmental sustainability: Renewable energy sources such as solar, wind, hydro, and geothermal power produce minimal to no greenhouse gas emissions, helping to combat climate change and reduce air pollution.\n",
      "\n",
      "2. Energy security and independence: Unlike fossil fuels, renewable energy sources are abundant and widely available, reducing the dependency on imported energy and increasing domestic energy production.\n",
      "\n",
      "3. Cost savings: Although the initial investment for renewable energy systems can be high, the operational costs are significantly lower than fossil fuel-based power generation. Over time, using renewable energy can lead to substantial cost savings.\n",
      "\n",
      "4. Job creation and economic growth: The renewable energy sector creates numerous job opportunities, from manufacturing and installation to maintenance and operation. Investing in renewable energy can stimulate economic growth and support local communities.\n",
      "\n",
      "5. Diversification of energy sources: Relying on a mix of renewable energy sources helps to diversify the energy portfolio and reduce the vulnerability to price fluctuations and supply disruptions associated with\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are the key benefits of using renewable energy?\" \n",
    "response = get_gpt_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b800ea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API stands for Application Programming Interface. It is a set of rules and protocols that allows different software applications to communicate and interact with each other. APIs define the methods and data formats that developers can use to request certain functionalities or access certain resources from a software application or service. APIs can be used to integrate different software systems, create mashups, or develop third-party applications that interact with existing platforms or services.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is api\" \n",
    "response = get_gpt_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8e039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT stands for \"Generative Pre-trained Transformer.\" It is a type of deep learning model that is designed to generate human-like text based on given input prompts. GPT models, like OpenAI's GPT-3, are trained on a large amount of text data and can be used for a variety of natural language processing tasks, such as language translation, chatbot development, content generation, and more.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"what is gpt\" \n",
    "response = get_gpt_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632feab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's an example code snippet in Python using the pandas library to impute missing values with the median:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load your dataset\n",
      "df = pd.read_csv('your_dataset.csv')\n",
      "\n",
      "# Compute the median for each column\n",
      "median_values = df.median()\n",
      "\n",
      "# Impute missing values with the median\n",
      "df_filled = df.fillna(median_values)\n",
      "\n",
      "# Display the imputed dataframe\n",
      "print(df_filled)\n",
      "```\n",
      "\n",
      "In this code, we first load the dataset using `pd.read_csv()`. Then, we calculate the median for each column using the `median()` method. Finally, we use the `fillna()` method to replace the missing values with the corresponding median values. The resulting imputed dataframe is stored in `df_filled`.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I have a dataset with missing values, and I want to impute them using the median. Could you please provide me with the code to perform this imputation using the median?\" \n",
    "response = get_gpt_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc69e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Game of Thrones\" is a popular fantasy television series based on the book series \"A Song of Ice and Fire\" by George R.R. Martin. The show is known for its complex characters, political intrigue, and epic battles. It takes place in the fictional continents of Westeros and Essos and follows the power struggles between noble families as they vie for control of the Iron Throne. The show has garnered a large and dedicated fanbase and has won numerous awards. If you have any specific questions about \"Game of Thrones,\" feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Games of thrones\" \n",
    "response = get_gpt_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39984f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e540139",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = 4\n",
    "c = a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15661c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
